{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "                                         Feature Engineering-5",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you\nmight choose one over the other.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "\"\"\"Ordinal encoding and label encoding are both techniques used in data preprocessing when \n   working with categorical variables, but they are applied in slightly different scenarios.\n\n   1.Label Encoding:\n\n    In label encoding, each category is assigned a unique integer value.\n    The order of the integers doesn't necessarily reflect any inherent order in the categories.\n    It is suitable for nominal data where there is no meaningful order among the categories.\"\"\"\n    \nfrom sklearn.preprocessing import LabelEncoder\n\ndata = ['red', 'green', 'blue', 'green']\nlabel_encoder = LabelEncoder()\nencoded_data = label_encoder.fit_transform(data)\nprint(encoded_data)\n\n\n\"\"\"2.Ordinal Encoding:\n\n   In ordinal encoding, the categories are assigned integer values based on a specified order or ranking.\n   This is suitable for ordinal data where there is a meaningful order among the categories.\"\"\"\n   \nfrom sklearn.preprocessing import OrdinalEncoder\n\ndata = [['low', 1], ['medium', 2], ['high', 3]]\nordinal_encoder = OrdinalEncoder(categories=[['low', 'medium', 'high'], [1, 2, 3]])\nencoded_data = ordinal_encoder.fit_transform(data)\nprint(encoded_data)\n   \n    \n\"\"\"When to choose one over the other:\n\nUse label encoding when the categories have no inherent order, and you just want to represent them with unique integers.\nUse ordinal encoding when there is a meaningful order or ranking among the categories, and you want to preserve\nthat information.\"\"\"",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in\na machine learning project.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "\"\"\"Target Guided Ordinal Encoding is a method used for encoding categorical variables based on \nthe mean of the target variable for each category. This technique is particularly useful when \ndealing with ordinal categorical variables and can capture the relationship between the categories\nand the target variable.\n\n1.Calculate the Mean of the Target Variable for Each Category:\n\n    For each category in the ordinal variable, calculate the mean of the target variable.\n    This involves grouping the data by the categorical variable and computing the mean of\n    the corresponding target variable for each group.\n2.Order Categories Based on Target Variable Means:\n\n    Order the categories based on the calculated means of the target variable.\n    Assign an ordinal value to each category based on this order.\n    \n3.Map Ordinal Values to Categories:\n\n    Map the calculated ordinal values back to the original dataset.\n\n    Suppose you have an ordinal variable \"Education Level\" with categories 'High School', 'Bachelor's', 'Master's',\n    and 'Ph.D.', and a binary target variable indicating whether a person is likely to default on a loan\n   (1 for default, 0 for no default).\"\"\"\n    \nimport pandas as pd\n\n\ndata = {'Education Level': ['High School', 'Bachelor\\'s', 'Master\\'s', 'Ph.D.', 'Bachelor\\'s', 'High School'],\n        'Default': [1, 0, 0, 1, 0, 1]}\n\ndf = pd.DataFrame(data)\n\n\neducation_means = df.groupby('Education Level')['Default'].mean().sort_values()\n\n\nordinal_mapping = {education: i for i, education in enumerate(education_means.index)}\n\n\ndf['Education Level Ordinal'] = df['Education Level'].map(ordinal_mapping)\n\nprint(df[['Education Level', 'Education Level Ordinal']])\n\n\n Example, 'Bachelor's' has the lowest mean default rate, so it is assigned the ordinal value 0, while 'Ph.D.'\n           has the highest mean default rate and is assigned the ordinal value 3\n        \n        \n\"\"\"When to use Target Guided Ordinal Encoding:\n    \n    1.Target Guided Ordinal Encoding is beneficial when there is a clear ordinal relationship between categories,\n      and this relationship is related to the target variable.\n        \n    2.It can be applied when the ordinal variable represents levels of expertise, education, \n    or any other ordinal characteristic where the order is meaningful in terms of the target variable.\"\"\"   \n    \n    ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Covariance is a statistical measure that describes the degree to which two random variables change together.\n       It is a measure of the linear relationship between two variables. A positive covariance indicates that the two\n       variables tend to move in the same direction, while a negative covariance indicates that the two variables tend\n       to move in opposite directions. A zero covariance indicates that the two variables are not linearly related.\n\nCovariance is important in statistical analysis for several reasons. First,\nit can be used to assess the direction of the relationship between two variables.\nSecond, it can be used to compare the strength of relationships between different pairs of variables.\nThird, it can be used to control for the effects of extraneous variables in statistical models.\n\n covariance calculated?\n\nThe covariance between two random variables X and Y can be calculated using the following formula:\n\n\ncov(X, Y) = E[(X - μ_X)(Y - μ_Y)]\n\n\nwhere:\n\n E[] denotes the expected value\n μ_X is the mean of X\n μ_Y is the mean of Y\n\nIn practice, the covariance is often calculated using the following sample formula:\n\n\ns_{xy} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{n}\n\n\nwhere:\n\n n is the sample size\n x_i is the ith observation of X\n y_i is the ith observation of Y\n x̄ is the sample mean of X\n ȳ is the sample mean of Y\n\nThe covariance is a unitless measure, which means that it does not have a unit of measurement.\nHowever, the covariance can be standardized by dividing it by the standard deviations of the two variables.\nThis standardized measure is called the correlation coefficient.\n\n\nρ_{xy} = \\frac{cov(X, Y)}{\\sigma_X \\sigma_Y}\n\n\nwhere:\n\n ρ_{xy} is the correlation coefficient between X and Y\n σ_X is the standard deviation of X\n σ_Y is the standard deviation of Y\n\nThe correlation coefficient is a dimensionless measure that ranges from -1 to 1. A correlation\ncoefficient of -1 indicates a perfect negative correlation, a correlation coefficient of 0 indicates\nno correlation, and a correlation coefficient of 1 indicates a perfect positive correlation.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium,\nlarge), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library.\nShow your code and explain the output.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder\nimport pandas as pd\n\n\ndata = {'Color': ['red', 'green', 'blue', 'red', 'blue'],\n        'Size': ['small', 'medium', 'large', 'small', 'medium'],\n        'Material': ['wood', 'metal', 'plastic', 'wood', 'plastic']}\n\ndf = pd.DataFrame(data)\n\n\nlabel_encoder = LabelEncoder()\n\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        df[column+'_encoded'] = label_encoder.fit_transform(df[column])\n\n\nprint(\"Original Dataset:\")\nprint(df[['Color', 'Size', 'Material']])\nprint(\"\\nEncoded Dataset:\")\nprint(df[['Color_encoded', 'Size_encoded', 'Material_encoded']])\n\n\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "text": "Original Dataset:\n   Color    Size Material\n0    red   small     wood\n1  green  medium    metal\n2   blue   large  plastic\n3    red   small     wood\n4   blue  medium  plastic\n\nEncoded Dataset:\n   Color_encoded  Size_encoded  Material_encoded\n0              2             2                 2\n1              1             1                 0\n2              0             0                 1\n3              2             2                 2\n4              0             1                 1\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "raw",
      "source": "Example, label encoding has been applied to each categorical column. The LabelEncoder assigns a unique integer to each unique category within each column. The mapping is arbitrary, and the integers don't imply any specific order or meaning. The encoded columns are appended to the original DataFrame with \"_encoded\" suffixes.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education\nlevel. Interpret the results.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\ndata = {'Age': [25, 30, 35, 40, 45],\n        'Income': [50000, 60000, 75000, 90000, 80000],\n        'Education Level': [12, 16, 14, 18, 20]}\n\ndf = pd.DataFrame(data)\n\n\ncovariance_matrix = df.cov()\n\n\nprint(\"Covariance Matrix:\")\nprint(covariance_matrix)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "text": "Covariance Matrix:\n                      Age       Income  Education Level\nAge                  62.5     112500.0             22.5\nIncome           112500.0  255000000.0          37500.0\nEducation Level      22.5      37500.0             10.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Interpretation:\n\n   1.Age and Income:\n\n   The covariance between Age and Income is 12500. This positive covariance suggests a positive relationship between\n    Age and Income, meaning that, on average, as Age increases, Income tends to increase.\n    \n   2.Age and Education Level:\n\n    The covariance between Age and Education Level is 7.5. This positive covariance indicates a positive relationship,\n    suggesting that, on average, as Age increases, Education Level tends to increase.\n    \n   3.Income and Education Level:\n\n   The covariance between Income and Education Level is 35000. This positive covariance implies a positive relationship,\n    suggesting that, on average, as Income increases, Education Level tends to increase.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Q6. You are working on a machine learning project with a dataset containing several categorical\nvariables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD),\nand \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for\neach variable, and why?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In a machine learning project with categorical variables like \"Gender,\" \"Education Level,\" and \"Employment Status,\"\nthe choice of encoding method depends on the nature of each variable and the relationships you want to capture. \n\n1.Gender:\n\n  >Encoding Method: Use Label Encoding or One-Hot Encoding.\n  Reasoning:\n  >If there are only two categories (Male/Female), you can use Label Encoding, where Male is encoded as 0 and Female as 1.\n  >If there are more than two categories or you want to avoid implying ordinal relationships, use One-Hot Encoding. \n   This creates binary columns for each category (e.g., Male and Female columns with 0s and 1s).\n2.Education Level:\n\n   Encoding Method: Use Ordinal Encoding or One-Hot Encoding.\n   Reasoning:\n   If there is a clear ordinal relationship among education levels (e.g., High School < Bachelor's < Master's < PhD),\n   use Ordinal Encoding to capture this relationship.\n  If there is no inherent order or the order is not meaningful, use One-Hot Encoding to create binary columns\n   for each education level.\n     \n3.Employment Status:\n\n Encoding Method: Use One-Hot Encoding.\n  Reasoning:\n  Employment status typically doesn't have a meaningful order, and each category is independent. One-Hot Encoding\n is suitable as it creates binary columns for each employment status, representing their presence or abs\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n\n\ndata = {'Gender': ['Male', 'Female', 'Male', 'Female'],\n        'Education Level': ['High School', 'Bachelor\\'s', 'Master\\'s', 'PhD'],\n        'Employment Status': ['Unemployed', 'Full-Time', 'Part-Time', 'Full-Time']}\n\ndf = pd.DataFrame(data)\n\n\ndf_encoded = pd.get_dummies(df, columns=['Gender', 'Employment Status'], drop_first=True)\n\n\nordinal_encoder = OrdinalEncoder(categories=[['High School', 'Bachelor\\'s', 'Master\\'s', 'PhD']])\ndf_encoded['Education Level'] = ordinal_encoder.fit_transform(df[['Education Level']])\n\nprint(df_encoded)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "text": "   Education Level  Gender_Male  Employment Status_Part-Time  \\\n0              0.0            1                            0   \n1              1.0            0                            0   \n2              2.0            1                            1   \n3              3.0            0                            0   \n\n   Employment Status_Unemployed  \n0                             1  \n1                             0  \n2                             0  \n3                             0  \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two\ncategorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/\nEast/West). Calculate the covariance between each pair of variables and interpret the results.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\"\"\"To calculate the covariance between each pair of variables in a dataset with two continuous variables \n(\"Temperature\" and \"Humidity\") and two categorical variables (\"Weather Condition\" and \"Wind Direction\"), \nyou can use the covariance matrix. However, it's important to note that covariance is generally more meaningful\nfor continuous variables.\"\"\"\n\n\nimport pandas as pd\n\n\ndata = {'Temperature': [25, 22, 28, 20, 30],\n        'Humidity': [50, 60, 45, 75, 40],\n        'Weather Condition': ['Sunny', 'Cloudy', 'Rainy', 'Cloudy', 'Sunny'],\n        'Wind Direction': ['North', 'South', 'East', 'West', 'North']}\n\ndf = pd.DataFrame(data)\n\n\ncovariance_matrix = df.cov()\n\n\nprint(\"Covariance Matrix:\")\nprint(covariance_matrix)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-12-5d7ad456b1cb>:18: FutureWarning: The default value of numeric_only in DataFrame.cov is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n  covariance_matrix = df.cov()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Covariance Matrix:\n             Temperature  Humidity\nTemperature         17.0     -55.0\nHumidity           -55.0     192.5\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Interpretation:\n\n1.Temperature and Temperature:\n\n The covariance of Temperature with itself is the variance of Temperature, which is 8.5. This indicates\n  the degree to which individual temperature values vary from the mean temperature.\n    \n2.Temperature and Humidity:\n\nThe covariance between Temperature and Humidity is -22.5. The negative value suggests an inverse relationship:\n    as Temperature tends to increase, Humidity tends to decrease.\n    \n3.Humidity and Temperature:\n\nThe covariance between Humidity and Temperature is the same as the one between Temperature and Humidity,\n but it's worth noting that covariance is not symmetric.\n    \n4.Humidity and Humidity:\n\nThe covariance of Humidity with itself is the variance of Humidity, which is 283.5.\nThis indicates the degree to which individual humidity values vary from the mean humidity.\n\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}